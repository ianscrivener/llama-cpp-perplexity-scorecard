# please describe you hardware briefly
# Macbook Pro M2 16GB
# Intel i9-xxxx, RTX4090, 64Gb RAM
# Runpod 8vCPU 31GB RAM, 1 x RTXA4000
HARDWARE_DESC=""

# full filepath to python project
LLAMA_CPP_PATH="/home/users/somebody/llama.cpp"

# model name
MODEL='open-llama-7b-q4_0.bin'

# model filepath
MODEL_PATH='/home/users/somebody/llama.cpp/models/7B'

# test corpus - download from here:
CORPUS='wiki.test.raw.406'

# set the number of lines for later reporting & analytics
CORPUS_LINES=406

# test corpus filepath
#CORPUS_PATH=''

# ./perplexty settings - see `./perplexity -h` for details
CONTEXT=512
BATCH=512
THREADS=4
GPU=1

#API = "https://faas-sfo3-7872a1dd.doserverless.co/api/v1/web/fn-0e980f16-1f90-45b6-95f9-3a85255c6239/llama_perplexity_api/v1"
